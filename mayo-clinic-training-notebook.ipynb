{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n\nimport IPython.display\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nfrom PIL import Image\nfrom glob import glob\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n#import Pyvips\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, train_test_split\nfrom skimage.filters import sobel\nfrom skimage import segmentation\nfrom skimage.color import label2rgb\nfrom skimage.color import rgb2hed, hed2rgb\nfrom skimage.exposure import rescale_intensity\nfrom skimage.measure import regionprops, regionprops_table\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import ndimage as ndi\nfrom matplotlib.patches import Rectangle\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\n\n\nimport torchvision\n\nfrom tqdm.auto import tqdm\nfrom tqdm import trange\nfrom time import sleep\nfrom functools import partial\nimport tifffile as tiff\n\nimport cv2 as cv\nfrom openslide import OpenSlide\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom pprint import pprint\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport gc\nimport torchvision.models as models\nimport copy\n\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\nfrom torch.cuda.amp import autocast, GradScaler\nImage.MAX_IMAGE_PIXELS = None\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-22T07:04:23.872139Z","iopub.execute_input":"2022-08-22T07:04:23.873021Z","iopub.status.idle":"2022-08-22T07:04:23.886113Z","shell.execute_reply.started":"2022-08-22T07:04:23.872981Z","shell.execute_reply":"2022-08-22T07:04:23.884775Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Loading data","metadata":{}},{"cell_type":"code","source":"transformed_train = pd.read_csv('../input/mayo-clinic-output/new_train.csv')\ntest = pd.read_csv('../input/mayo-clinic-strip-ai/test.csv')\ntrain, valid = train_test_split(transformed_train, test_size=0.2)\nclasses_name = [\"LAA\",\"CE\"]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T07:04:24.440794Z","iopub.execute_input":"2022-08-22T07:04:24.441135Z","iopub.status.idle":"2022-08-22T07:04:24.472352Z","shell.execute_reply.started":"2022-08-22T07:04:24.441105Z","shell.execute_reply":"2022-08-22T07:04:24.470898Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/506952545.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformed_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/mayo-clinic-output/new_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/mayo-clinic-strip-ai/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclasses_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"LAA\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"CE\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/mayo-clinic-output/new_train.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/mayo-clinic-output/new_train.csv'","output_type":"error"}]},{"cell_type":"markdown","source":"# Test Transformation ","metadata":{}},{"cell_type":"code","source":"def rezie_image(image):\n    resized_image = cv.resize(image,(int(image.shape[1]/33),int(image.shape[0]/33)),interpolation= cv.INTER_LINEAR)\n    return resized_image\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T06:20:39.532981Z","iopub.execute_input":"2022-08-22T06:20:39.533313Z","iopub.status.idle":"2022-08-22T06:20:39.539558Z","shell.execute_reply.started":"2022-08-22T06:20:39.533281Z","shell.execute_reply":"2022-08-22T06:20:39.538371Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def grey_resize(image):\n    gray_resized_image = cv.cvtColor(image, cv.COLOR_RGB2GRAY)    \n    return gray_resized_image\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T06:20:39.542240Z","iopub.execute_input":"2022-08-22T06:20:39.542942Z","iopub.status.idle":"2022-08-22T06:20:39.549572Z","shell.execute_reply.started":"2022-08-22T06:20:39.542908Z","shell.execute_reply":"2022-08-22T06:20:39.548522Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def labeled_segment(grey_resized_image):\n    elevation_map = sobel(grey_resized_image)\n    markers = np.zeros_like(grey_resized_image)\n    markers[grey_resized_image >= grey_resized_image.mean()] = 1\n    markers[grey_resized_image < grey_resized_image.mean()] = 2\n    segmented_img = segmentation.watershed(elevation_map, markers)\n    filled_segments = ndi.binary_fill_holes(segmented_img - 1)\n    labeled_segments, _ = ndi.label(filled_segments)\n    return labeled_segments\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T06:20:39.550895Z","iopub.execute_input":"2022-08-22T06:20:39.551496Z","iopub.status.idle":"2022-08-22T06:20:39.559551Z","shell.execute_reply.started":"2022-08-22T06:20:39.551448Z","shell.execute_reply":"2022-08-22T06:20:39.558443Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def plot_labeled_segments(labeled_segments, resized_gray_img):\n    image_label_overlay = label2rgb(labeled_segments, image=resized_gray_img, bg_label=0)\n    fig, ax = plt.subplots(figsize=(10, 8))\n    ax.imshow(image_label_overlay, cmap=plt.cm.gray)\n    ax.set_title('segmentation')\n    ax.axis('off')\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T06:20:39.560954Z","iopub.execute_input":"2022-08-22T06:20:39.561590Z","iopub.status.idle":"2022-08-22T06:20:39.568235Z","shell.execute_reply.started":"2022-08-22T06:20:39.561556Z","shell.execute_reply":"2022-08-22T06:20:39.567358Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def get_object_coordinates(labeled_segments):\n    properties =['area','bbox','convex_area','bbox_area', 'major_axis_length', 'minor_axis_length', 'eccentricity']\n    df = pd.DataFrame(regionprops_table(labeled_segments, properties=properties))\n    standard_scaler = StandardScaler()\n    scaled_area = standard_scaler.fit_transform(df.area.values.reshape(-1,1))\n    df['scaled_area'] = scaled_area\n    df.sort_values(by=\"scaled_area\", ascending=False, inplace=True)\n    objects = df[df['scaled_area']>=.75]\n    object_coordinates = [(row['bbox-0'],row['bbox-1'],row['bbox-2'],row['bbox-3'] )for index, row in objects.iterrows()]\n    return object_coordinates\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T06:20:39.569814Z","iopub.execute_input":"2022-08-22T06:20:39.570227Z","iopub.status.idle":"2022-08-22T06:20:39.578788Z","shell.execute_reply.started":"2022-08-22T06:20:39.570194Z","shell.execute_reply":"2022-08-22T06:20:39.577805Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def plot_object_coordinates(object_coordinates, resized_image):\n    fig, ax = plt.subplots(1,1, figsize=(18, 16), dpi = 80)\n    for blob in object_coordinates:\n        width = blob[3] - blob[1]\n        height = blob[2] - blob[0]\n        patch = Rectangle((blob[1],blob[0]), width, height, edgecolor='r', facecolor='none')\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T06:20:39.580306Z","iopub.execute_input":"2022-08-22T06:20:39.580753Z","iopub.status.idle":"2022-08-22T06:20:39.591964Z","shell.execute_reply.started":"2022-08-22T06:20:39.580718Z","shell.execute_reply":"2022-08-22T06:20:39.590788Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def save_objects(object_coordinates, image, image_name, count):\n    plt.figure(figsize=(10,18))\n    for i in range(len(object_coordinates)):\n        coordinates = object_coordinates[i]\n        object_image = image[int(coordinates[0]):int(coordinates[2]), int(coordinates[1]):int(coordinates[3])]\n        image_new_name = image_name + \"_\" + str(i)\n        new_test[\"image_name\"].append(image_new_name)\n        new_test[\"image_count\"].append(count)\n        cv.imwrite(os.path.join(\"./\", f\"{image_new_name}.jpg\"), object_image)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T06:20:39.594654Z","iopub.execute_input":"2022-08-22T06:20:39.595518Z","iopub.status.idle":"2022-08-22T06:20:39.603406Z","shell.execute_reply.started":"2022-08-22T06:20:39.595469Z","shell.execute_reply":"2022-08-22T06:20:39.602397Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"test_path = \"../input/mayo-clinic-strip-ai/test\"\nImage_names = test['image_id'].values\nnew_test={\"image_count\":[],\"image_name\":[]}\ncount = 1\nscale = 4\nfor image_name in Image_names:\n    image = tiff.imread(os.path.join(test_path, f\"{image_name}.tif\"))\n    resized_image=rezie_image(image)\n    del image\n    gc.collect()\n    grey_resized_image = grey_resize(resized_image)\n    labeled_segments = labeled_segment(grey_resized_image)\n    object_coordinates = get_object_coordinates(labeled_segments)\n    save_objects(object_coordinates, resized_image, image_name,count)\n    \nnew_test=pd.DataFrame.from_dict(new_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T06:20:39.607323Z","iopub.execute_input":"2022-08-22T06:20:39.608858Z","iopub.status.idle":"2022-08-22T06:21:58.847183Z","shell.execute_reply.started":"2022-08-22T06:20:39.608830Z","shell.execute_reply":"2022-08-22T06:21:58.846216Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x1296 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x1296 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x1296 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x1296 with 0 Axes>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Loader","metadata":{}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, path, df,phase, transform=None):\n        self.df = df\n        self.path = path\n        self.Image_names = df['image_name'].values\n        self.phase = phase\n        if phase ==\"train\":\n            self.labels = df['label'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.Image_names[idx]\n        img= Image.open(os.path.join(self.path, f\"{file_name}.jpg\"))\n        if self.transform:\n            image=self.transform(img)\n        if self.phase ==\"train\":\n            label = self.labels[idx]\n            return image, torch.tensor(label), file_name\n        else:\n            return image, file_name\n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-22T06:34:25.269569Z","iopub.execute_input":"2022-08-22T06:34:25.270161Z","iopub.status.idle":"2022-08-22T06:34:25.278234Z","shell.execute_reply.started":"2022-08-22T06:34:25.270124Z","shell.execute_reply":"2022-08-22T06:34:25.276996Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# Transforms","metadata":{}},{"cell_type":"code","source":"batch_size=80\ndata_transform = transforms.Compose([\n        transforms.Resize((256,256)),\n        transforms.ToTensor(), transforms.RandomHorizontalFlip(),transforms.RandomVerticalFlip(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\ntrain_dataset = TrainDataset(\"../input/mayo-clinic-output/\", train,phase=\"train\", transform = data_transform)\nvalid_dataset = TrainDataset(\"../input/mayo-clinic-output/\", valid,phase=\"train\", transform = data_transform)\ntest_dataset = TrainDataset(\"./\", new_test,phase=\"test\", transform = data_transform)\n\ntrain_dl = torch.utils.data.DataLoader(train_dataset,\n                                             batch_size=batch_size, shuffle=True,\n                                             num_workers=0)\nvalid_dl = torch.utils.data.DataLoader(valid_dataset,\n                                             batch_size=batch_size, shuffle=True,\n                                             num_workers=0)\ntest_dl = torch.utils.data.DataLoader(test_dataset,\n                                             batch_size=1, shuffle=True,\n                                             num_workers=0)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T07:01:50.078754Z","iopub.execute_input":"2022-08-22T07:01:50.079758Z","iopub.status.idle":"2022-08-22T07:01:50.090595Z","shell.execute_reply.started":"2022-08-22T07:01:50.079720Z","shell.execute_reply":"2022-08-22T07:01:50.089488Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def imshow(axis, inp):\n    \"\"\"Denormalize and show\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    axis.imshow(inp)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T07:01:50.467746Z","iopub.execute_input":"2022-08-22T07:01:50.468552Z","iopub.status.idle":"2022-08-22T07:01:50.474959Z","shell.execute_reply.started":"2022-08-22T07:01:50.468484Z","shell.execute_reply":"2022-08-22T07:01:50.473918Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# PreTrained Model","metadata":{}},{"cell_type":"code","source":"use_gpu = torch.cuda.is_available()\nmodel_ft = torchvision.models.resnet50(pretrained=False)\nmodel_ft.load_state_dict(torch.load(\"../input/pretrained-model-weights-pytorch/resnet50-19c8e357.pth\"))\n#model_ft = models.resnet50(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\nmodel_ft=model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\nexp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T07:01:51.212944Z","iopub.execute_input":"2022-08-22T07:01:51.213626Z","iopub.status.idle":"2022-08-22T07:01:51.877551Z","shell.execute_reply.started":"2022-08-22T07:01:51.213575Z","shell.execute_reply":"2022-08-22T07:01:51.876339Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def train_model(dataloders, model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n    best_model_wts = model.state_dict()\n    best_acc = 0.0\n    dataset_sizes = {'train': len(dataloders['train'].dataset), \n                     'valid': len(dataloders['valid'].dataset)}\n\n    for epoch in range(num_epochs):\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                scheduler.step()\n                model.train(True)\n            else:\n                model.train(False)\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels, _ in dataloders[phase]:\n                if use_gpu:\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n                else:\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                outputs = model(inputs)\n                _, preds = torch.max(outputs.data, 1)\n                loss = criterion(outputs, labels)\n\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n                running_loss += loss.data\n                running_corrects += torch.sum(preds == labels.data)\n                del inputs, labels\n                torch.cuda.empty_cache()\n                gc.collect()\n            \n            if phase == 'train':\n                train_epoch_loss = running_loss / dataset_sizes[phase]\n                train_epoch_acc = running_corrects / dataset_sizes[phase]\n            else:\n                valid_epoch_loss = running_loss / dataset_sizes[phase]\n                valid_epoch_acc = running_corrects / dataset_sizes[phase]\n                \n            if phase == 'valid' and valid_epoch_acc > best_acc:\n                best_acc = valid_epoch_acc\n                best_model_wts = model.state_dict()\n\n        print('Epoch [{}/{}] train loss: {:.4f} acc: {:.4f} ' \n              'valid loss: {:.4f} acc: {:.4f}'.format(\n                epoch, num_epochs - 1,\n                train_epoch_loss, train_epoch_acc, \n                valid_epoch_loss, valid_epoch_acc))\n            \n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-08-22T07:01:52.079933Z","iopub.execute_input":"2022-08-22T07:01:52.080257Z","iopub.status.idle":"2022-08-22T07:01:52.093033Z","shell.execute_reply.started":"2022-08-22T07:01:52.080226Z","shell.execute_reply":"2022-08-22T07:01:52.091970Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"dloaders = {'train':train_dl, 'valid':valid_dl}\nstart_time = time.time()\nmodel = train_model(dloaders, model_ft, criterion, optimizer, exp_lr_scheduler, num_epochs=20)\ndel model_ft\ntorch.cuda.empty_cache()\ngc.collect()\nprint('Training time: {:10f} minutes'.format((time.time()-start_time)/60))","metadata":{"execution":{"iopub.status.busy":"2022-08-22T07:01:52.895537Z","iopub.execute_input":"2022-08-22T07:01:52.896172Z","iopub.status.idle":"2022-08-22T07:02:30.792671Z","shell.execute_reply.started":"2022-08-22T07:01:52.896137Z","shell.execute_reply":"2022-08-22T07:02:30.791157Z"},"trusted":true},"execution_count":34,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/930550822.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvalid_dl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_17/1117774683.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(dataloders, model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    443\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 444\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 160.00 MiB (GPU 0; 15.90 GiB total capacity; 14.81 GiB already allocated; 77.75 MiB free; 14.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"],"ename":"RuntimeError","evalue":"CUDA out of memory. Tried to allocate 160.00 MiB (GPU 0; 15.90 GiB total capacity; 14.81 GiB already allocated; 77.75 MiB free; 14.99 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error"}]},{"cell_type":"code","source":"def visualize_model(dataloders, model, num_images=25):\n    cnt = 0\n    fig = plt.figure(1, figsize=(20, 20))\n    grid = ImageGrid(fig, 111, nrows_ncols=(5, 5), axes_pad=0.05)\n    for i, (inputs, labels, file_name) in enumerate(dataloders['valid']):\n        if use_gpu:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n        else:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n        outputs = model(inputs)\n        _, preds = torch.max(outputs.data, 1)\n        sm = torch.nn.Softmax()\n        probabilities = sm(outputs).tolist()\n        rounded_prob = [np.round(num, 1) for num in probabilities]\n        for j in range(inputs.size()[0]):\n            ax = grid[cnt]\n            imshow(ax, inputs.cpu().data[j])\n            ax.text(10, 20, 'ID: {} '.format(file_name[j]),color='k', backgroundcolor='w', alpha=0.8,size=\"small\")\n            ax.text(10, 230, 'Predicted {} || Actual {}'.format(classes_name[preds[j]], classes_name[labels.data[j]]), \n                    color='k', backgroundcolor='w', alpha=0.8,size=\"small\")\n            ax.text(10, 245,rounded_prob[j],color='k', backgroundcolor='w', alpha=0.8,size=\"small\")\n            cnt += 1\n            if cnt == num_images:\n                del inputs, labels\n                torch.cuda.empty_cache()\n                gc.collect()\n                return","metadata":{"execution":{"iopub.status.busy":"2022-08-22T06:21:58.884011Z","iopub.status.idle":"2022-08-22T06:21:58.884760Z","shell.execute_reply.started":"2022-08-22T06:21:58.884502Z","shell.execute_reply":"2022-08-22T06:21:58.884526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualize_model(dloaders, model)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:47:39.337486Z","iopub.execute_input":"2022-08-21T20:47:39.339412Z","iopub.status.idle":"2022-08-21T20:47:39.351588Z","shell.execute_reply.started":"2022-08-21T20:47:39.339323Z","shell.execute_reply":"2022-08-21T20:47:39.350542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"def submission(dataloders, model):\n    prob_data = {\"ID\":[],\"prob\":[]}\n    if dataloders ==dloaders:\n        dataloders = dataloders['valid']\n        \n    for i, (inputs, file_name) in enumerate(dataloders):\n        if use_gpu:\n            inputs = inputs.to(device)\n            \n        outputs = model(inputs)\n        _, preds = torch.max(outputs.data, 1)\n        sm = torch.nn.Softmax()\n        probabilities = sm(outputs).tolist()\n        rounded_prob = [np.round(num, 1) for num in probabilities]\n        \n        for i in range(inputs.size()[0]):\n            prob_data[\"ID\"].append(file_name[i])\n            prob_data[\"prob\"].append(rounded_prob[i])\n            \n        del inputs\n        torch.cuda.empty_cache()\n        gc.collect()\n    prob_data= pd.DataFrame.from_dict(prob_data)\n    prob_data['patient_id'], prob_data['image_nu'],prob_data['split_nu'] = prob_data['ID'].str.split('_').str\n    prob_data[['LAA','CE']] = pd.DataFrame(prob_data.prob.tolist(), index= prob_data.index)\n    prob_data_submission = prob_data.drop(['ID', 'prob','image_nu','split_nu'], axis=1)\n    avg = prob_data_submission.groupby('patient_id',as_index=False).mean()\n    avg = avg[['patient_id','CE','LAA']]\n    return avg\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:52:24.782750Z","iopub.execute_input":"2022-08-21T20:52:24.783114Z","iopub.status.idle":"2022-08-21T20:52:24.794248Z","shell.execute_reply.started":"2022-08-21T20:52:24.783082Z","shell.execute_reply":"2022-08-21T20:52:24.793114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub=submission(test_dl, model)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:52:24.985736Z","iopub.execute_input":"2022-08-21T20:52:24.986771Z","iopub.status.idle":"2022-08-21T21:04:35.025879Z","shell.execute_reply.started":"2022-08-21T20:52:24.986722Z","shell.execute_reply":"2022-08-21T21:04:35.024910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv',index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-21T20:49:51.516103Z","iopub.execute_input":"2022-08-21T20:49:51.516734Z","iopub.status.idle":"2022-08-21T20:49:51.526510Z","shell.execute_reply.started":"2022-08-21T20:49:51.516697Z","shell.execute_reply":"2022-08-21T20:49:51.525411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(torch.cuda.memory_summary())","metadata":{"execution":{"iopub.status.busy":"2022-08-21T21:08:47.146924Z","iopub.execute_input":"2022-08-21T21:08:47.147630Z","iopub.status.idle":"2022-08-21T21:08:47.156367Z","shell.execute_reply.started":"2022-08-21T21:08:47.147568Z","shell.execute_reply":"2022-08-21T21:08:47.155177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}