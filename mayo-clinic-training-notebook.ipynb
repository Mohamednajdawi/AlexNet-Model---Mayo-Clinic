{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n\nimport IPython.display\n\nimport os\nimport math\nimport time\nimport PIL\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nfrom PIL import Image\nfrom glob import glob\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n#import Pyvips\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, train_test_split\nfrom skimage.filters import sobel\nfrom skimage import segmentation\nfrom skimage.color import label2rgb\nfrom skimage.color import rgb2hed, hed2rgb\nfrom skimage.exposure import rescale_intensity\nfrom skimage.measure import regionprops, regionprops_table\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import ndimage as ndi\nfrom matplotlib.patches import Rectangle\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\n\n\nimport torchvision\n\nfrom tqdm.auto import tqdm\nfrom tqdm import trange\nfrom time import sleep\nfrom functools import partial\nimport tifffile as tiff\n\nimport cv2 as cv\nfrom openslide import OpenSlide\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom pprint import pprint\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport gc\nimport torchvision.models as models\nimport copy\n\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\nfrom torch.cuda.amp import autocast, GradScaler\nImage.MAX_IMAGE_PIXELS = None\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-23T23:19:06.761052Z","iopub.execute_input":"2022-08-23T23:19:06.761858Z","iopub.status.idle":"2022-08-23T23:19:06.778305Z","shell.execute_reply.started":"2022-08-23T23:19:06.761791Z","shell.execute_reply":"2022-08-23T23:19:06.777128Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Loading data","metadata":{}},{"cell_type":"code","source":"transformed_train = pd.read_csv('../input/mayo-clinic-output/new_train.csv')\ntest = pd.read_csv('../input/mayo-clinic-strip-ai/test.csv')\ntrain, valid = train_test_split(transformed_train, test_size=0.2)\nclasses_name = [\"LAA\",\"CE\"]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:19:07.637773Z","iopub.execute_input":"2022-08-23T23:19:07.638416Z","iopub.status.idle":"2022-08-23T23:19:07.660754Z","shell.execute_reply.started":"2022-08-23T23:19:07.638382Z","shell.execute_reply":"2022-08-23T23:19:07.659932Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Test Transformation ","metadata":{}},{"cell_type":"code","source":"def rezie_image(image):\n    resized_image = cv.resize(image,(int(image.shape[1]/100),int(image.shape[0]/100)),interpolation= cv.INTER_LINEAR)\n    return resized_image\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:19:08.296072Z","iopub.execute_input":"2022-08-23T23:19:08.296409Z","iopub.status.idle":"2022-08-23T23:19:08.301715Z","shell.execute_reply.started":"2022-08-23T23:19:08.296378Z","shell.execute_reply":"2022-08-23T23:19:08.300621Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def grey_resize(image):\n    gray_resized_image = cv.cvtColor(image, cv.COLOR_RGB2GRAY)    \n    return gray_resized_image\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:19:10.577560Z","iopub.execute_input":"2022-08-23T23:19:10.578026Z","iopub.status.idle":"2022-08-23T23:19:10.583491Z","shell.execute_reply.started":"2022-08-23T23:19:10.577982Z","shell.execute_reply":"2022-08-23T23:19:10.582358Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def labeled_segment(grey_resized_image):\n    elevation_map = sobel(grey_resized_image)\n    markers = np.zeros_like(grey_resized_image)\n    markers[grey_resized_image >= grey_resized_image.mean()] = 1\n    markers[grey_resized_image < grey_resized_image.mean()] = 2\n    segmented_img = segmentation.watershed(elevation_map, markers)\n    filled_segments = ndi.binary_fill_holes(segmented_img - 1)\n    labeled_segments, _ = ndi.label(filled_segments)\n    return labeled_segments\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:19:10.747904Z","iopub.execute_input":"2022-08-23T23:19:10.748210Z","iopub.status.idle":"2022-08-23T23:19:10.754968Z","shell.execute_reply.started":"2022-08-23T23:19:10.748183Z","shell.execute_reply":"2022-08-23T23:19:10.753869Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def plot_labeled_segments(labeled_segments, resized_gray_img):\n    image_label_overlay = label2rgb(labeled_segments, image=resized_gray_img, bg_label=0)\n    fig, ax = plt.subplots(figsize=(10, 8))\n    ax.imshow(image_label_overlay, cmap=plt.cm.gray)\n    ax.set_title('segmentation')\n    ax.axis('off')\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:19:10.838265Z","iopub.execute_input":"2022-08-23T23:19:10.838773Z","iopub.status.idle":"2022-08-23T23:19:10.844768Z","shell.execute_reply.started":"2022-08-23T23:19:10.838742Z","shell.execute_reply":"2022-08-23T23:19:10.843879Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def get_object_coordinates(labeled_segments):\n    properties =['area','bbox','convex_area','bbox_area', 'major_axis_length', 'minor_axis_length', 'eccentricity']\n    df = pd.DataFrame(regionprops_table(labeled_segments, properties=properties))\n    standard_scaler = StandardScaler()\n    scaled_area = standard_scaler.fit_transform(df.area.values.reshape(-1,1))\n    df['scaled_area'] = scaled_area\n    df.sort_values(by=\"scaled_area\", ascending=False, inplace=True)\n    objects = df[df['scaled_area']>=.75]\n    object_coordinates = [(row['bbox-0'],row['bbox-1'],row['bbox-2'],row['bbox-3'] )for index, row in objects.iterrows()]\n    return object_coordinates\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:19:11.767810Z","iopub.execute_input":"2022-08-23T23:19:11.768161Z","iopub.status.idle":"2022-08-23T23:19:11.775378Z","shell.execute_reply.started":"2022-08-23T23:19:11.768132Z","shell.execute_reply":"2022-08-23T23:19:11.774404Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def plot_object_coordinates(object_coordinates, resized_image):\n    fig, ax = plt.subplots(1,1, figsize=(18, 16), dpi = 80)\n    for blob in object_coordinates:\n        width = blob[3] - blob[1]\n        height = blob[2] - blob[0]\n        patch = Rectangle((blob[1],blob[0]), width, height, edgecolor='r', facecolor='none')\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:19:12.397199Z","iopub.execute_input":"2022-08-23T23:19:12.397966Z","iopub.status.idle":"2022-08-23T23:19:12.404146Z","shell.execute_reply.started":"2022-08-23T23:19:12.397930Z","shell.execute_reply":"2022-08-23T23:19:12.402906Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def save_objects(object_coordinates, image, image_name, count):\n    plt.figure(figsize=(10,18))\n    for i in range(len(object_coordinates)):\n        coordinates = object_coordinates[i]\n        object_image = image[int(coordinates[0]):int(coordinates[2]), int(coordinates[1]):int(coordinates[3])]\n        image_new_name = image_name + \"_\" + str(i)\n        new_test[\"image_name\"].append(image_new_name)\n        new_test[\"image_count\"].append(count)\n        cv.imwrite(os.path.join(\"./\", f\"{image_new_name}.jpg\"), object_image)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:19:12.700383Z","iopub.execute_input":"2022-08-23T23:19:12.700863Z","iopub.status.idle":"2022-08-23T23:19:12.708182Z","shell.execute_reply.started":"2022-08-23T23:19:12.700812Z","shell.execute_reply":"2022-08-23T23:19:12.706495Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"test_path = \"../input/mayo-clinic-strip-ai/test\"\nImage_names = test['image_id'].values\nnew_test={\"image_count\":[],\"image_name\":[]}\ncount = 1\nscale = 4\nfor image_name in Image_names:\n    image = tiff.imread(os.path.join(test_path, f\"{image_name}.tif\"))\n    resized_image=rezie_image(image)\n    del image\n    gc.collect()\n    grey_resized_image = grey_resize(resized_image)\n    labeled_segments = labeled_segment(grey_resized_image)\n    del grey_resized_image\n    gc.collect()\n    object_coordinates = get_object_coordinates(labeled_segments)\n    del labeled_segments\n    gc.collect()\n    save_objects(object_coordinates, resized_image, image_name,count)\n    del object_coordinates\n    gc.collect()\nnew_test=pd.DataFrame.from_dict(new_test)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:19:14.140496Z","iopub.execute_input":"2022-08-23T23:19:14.140875Z","iopub.status.idle":"2022-08-23T23:20:08.311143Z","shell.execute_reply.started":"2022-08-23T23:19:14.140819Z","shell.execute_reply":"2022-08-23T23:20:08.310054Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x1296 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x1296 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x1296 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x1296 with 0 Axes>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Data Loader","metadata":{}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, path, df,phase, transform=None):\n        self.df = df\n        self.path = path\n        self.Image_names = df['image_name'].values\n        self.phase = phase\n        if phase ==\"train\":\n            self.labels = df['label'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.Image_names[idx]\n        img= Image.open(os.path.join(self.path, f\"{file_name}.jpg\"))\n        if self.transform:\n            image=self.transform(img)\n        if self.phase ==\"train\":\n            label = self.labels[idx]\n            return image, torch.tensor(label), file_name\n        else:\n            return image, file_name\n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:20:16.921762Z","iopub.execute_input":"2022-08-23T23:20:16.922693Z","iopub.status.idle":"2022-08-23T23:20:16.933936Z","shell.execute_reply.started":"2022-08-23T23:20:16.922640Z","shell.execute_reply":"2022-08-23T23:20:16.932878Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Transforms","metadata":{}},{"cell_type":"code","source":"batch_size=64\ndata_transform = transforms.Compose([\n        transforms.Resize((256,256)),\n        transforms.ToTensor(), transforms.RandomHorizontalFlip(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\ntrain_dataset = TrainDataset(\"../input/mayo-clinic-output/\", train,phase=\"train\", transform = data_transform)\nvalid_dataset = TrainDataset(\"../input/mayo-clinic-output/\", valid,phase=\"train\", transform = data_transform)\ntest_dataset = TrainDataset(\"./\", new_test,phase=\"test\", transform = data_transform)\n\ntrain_dl = torch.utils.data.DataLoader(train_dataset,\n                                             batch_size=batch_size, shuffle=True,\n                                             num_workers=0)\nvalid_dl = torch.utils.data.DataLoader(valid_dataset,\n                                             batch_size=batch_size, shuffle=True,\n                                             num_workers=0)\ntest_dl = torch.utils.data.DataLoader(test_dataset,\n                                             batch_size=1, shuffle=True,\n                                             num_workers=0)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:20:17.707603Z","iopub.execute_input":"2022-08-23T23:20:17.707958Z","iopub.status.idle":"2022-08-23T23:20:17.722392Z","shell.execute_reply.started":"2022-08-23T23:20:17.707928Z","shell.execute_reply":"2022-08-23T23:20:17.721195Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def imshow(axis, inp):\n    \"\"\"Denormalize and show\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    axis.imshow(inp)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:20:19.359982Z","iopub.execute_input":"2022-08-23T23:20:19.361023Z","iopub.status.idle":"2022-08-23T23:20:19.367829Z","shell.execute_reply.started":"2022-08-23T23:20:19.360972Z","shell.execute_reply":"2022-08-23T23:20:19.366475Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"# PreTrained Model","metadata":{}},{"cell_type":"code","source":"use_gpu = torch.cuda.is_available()\nmodel_ft = torchvision.models.resnet50(pretrained=False)\nmodel_ft.load_state_dict(torch.load(\"../input/pretrained-model-weights-pytorch/resnet50-19c8e357.pth\"))\n#model_ft = models.resnet50(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\nmodel_ft=model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\nexp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:24:29.343057Z","iopub.execute_input":"2022-08-23T23:24:29.343445Z","iopub.status.idle":"2022-08-23T23:24:30.310375Z","shell.execute_reply.started":"2022-08-23T23:24:29.343397Z","shell.execute_reply":"2022-08-23T23:24:30.308883Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def train_model(dataloders, model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n    best_model_wts = model.state_dict()\n    best_acc = 0.0\n    dataset_sizes = {'train': len(dataloders['train'].dataset), \n                     'valid': len(dataloders['valid'].dataset)}\n\n    for epoch in range(num_epochs):\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                scheduler.step()\n                model.train(True)\n            else:\n                model.train(False)\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels, _ in dataloders[phase]:\n                if use_gpu:\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n                    \n                optimizer.zero_grad()\n\n                outputs = model(inputs)\n                _, preds = torch.max(outputs.data, 1)\n                loss = criterion(outputs, labels)\n\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n                running_loss += loss.data\n                running_corrects += torch.sum(preds == labels.data)\n                del inputs, labels\n                torch.cuda.empty_cache()\n                gc.collect()\n                time.sleep(1)\n                torch.cuda.empty_cache()\n                gc.collect()\n                time.sleep(1)\n                torch.cuda.empty_cache()\n                gc.collect()\n            \n            if phase == 'train':\n                train_epoch_loss = running_loss / dataset_sizes[phase]\n                train_epoch_acc = running_corrects / dataset_sizes[phase]\n            else:\n                valid_epoch_loss = running_loss / dataset_sizes[phase]\n                valid_epoch_acc = running_corrects / dataset_sizes[phase]\n                \n            if phase == 'valid' and valid_epoch_acc > best_acc:\n                best_acc = valid_epoch_acc\n                best_model_wts = model.state_dict()\n\n        print('Epoch [{}/{}] train loss: {:.4f} acc: {:.4f} ' \n              'valid loss: {:.4f} acc: {:.4f}'.format(\n                epoch, num_epochs - 1,\n                train_epoch_loss, train_epoch_acc, \n                valid_epoch_loss, valid_epoch_acc))\n            \n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:24:35.389767Z","iopub.execute_input":"2022-08-23T23:24:35.390301Z","iopub.status.idle":"2022-08-23T23:24:35.402955Z","shell.execute_reply.started":"2022-08-23T23:24:35.390266Z","shell.execute_reply":"2022-08-23T23:24:35.401739Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"dloaders = {'train':train_dl, 'valid':valid_dl}\nstart_time = time.time()\nmodel = train_model(dloaders, model_ft, criterion, optimizer, exp_lr_scheduler, num_epochs=20)\ndel model_ft\ntorch.cuda.empty_cache()\ngc.collect()\nprint('Training time: {:10f} minutes'.format((time.time()-start_time)/60))","metadata":{"execution":{"iopub.status.busy":"2022-08-23T23:24:36.040391Z","iopub.execute_input":"2022-08-23T23:24:36.040736Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch [0/19] train loss: 0.0132 acc: 0.6113 valid loss: 0.0148 acc: 0.7081\n","output_type":"stream"}]},{"cell_type":"code","source":"def visualize_model(dataloders, model, num_images=25):\n    cnt = 0\n    fig = plt.figure(1, figsize=(20, 20))\n    grid = ImageGrid(fig, 111, nrows_ncols=(5, 5), axes_pad=0.05)\n    for i, (inputs, labels, file_name) in enumerate(dataloders['valid']):\n        if use_gpu:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n        else:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n        outputs = model(inputs)\n        _, preds = torch.max(outputs.data, 1)\n        sm = torch.nn.Softmax()\n        probabilities = sm(outputs).tolist()\n        rounded_prob = [np.round(num, 1) for num in probabilities]\n        for j in range(inputs.size()[0]):\n            ax = grid[cnt]\n            imshow(ax, inputs.cpu().data[j])\n            ax.text(10, 20, 'ID: {} '.format(file_name[j]),color='k', backgroundcolor='w', alpha=0.8,size=\"small\")\n            ax.text(10, 230, 'Predicted {} || Actual {}'.format(classes_name[preds[j]], classes_name[labels.data[j]]), \n                    color='k', backgroundcolor='w', alpha=0.8,size=\"small\")\n            ax.text(10, 245,rounded_prob[j],color='k', backgroundcolor='w', alpha=0.8,size=\"small\")\n            cnt += 1\n            if cnt == num_images:\n                del inputs, labels\n                torch.cuda.empty_cache()\n                gc.collect()\n                return","metadata":{"execution":{"iopub.status.busy":"2022-08-23T21:47:02.925134Z","iopub.status.idle":"2022-08-23T21:47:02.926354Z","shell.execute_reply.started":"2022-08-23T21:47:02.926084Z","shell.execute_reply":"2022-08-23T21:47:02.926108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#visualize_model(dloaders, model)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T21:18:49.324011Z","iopub.execute_input":"2022-08-22T21:18:49.325135Z","iopub.status.idle":"2022-08-22T21:18:49.332816Z","shell.execute_reply.started":"2022-08-22T21:18:49.325099Z","shell.execute_reply":"2022-08-22T21:18:49.331806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"def submission(dataloders, model):\n    prob_data = {\"ID\":[],\"prob\":[]}\n    if dataloders ==dloaders:\n        dataloders = dataloders['valid']\n        \n    for i, (inputs, file_name) in enumerate(dataloders):\n        if use_gpu:\n            inputs = inputs.to(device)\n            \n        outputs = model(inputs)\n        _, preds = torch.max(outputs.data, 1)\n        sm = torch.nn.Softmax()\n        probabilities = sm(outputs).tolist()\n        rounded_prob = [np.round(num, 1) for num in probabilities]\n        \n        for i in range(inputs.size()[0]):\n            prob_data[\"ID\"].append(file_name[i])\n            prob_data[\"prob\"].append(rounded_prob[i])\n            \n        del inputs\n        torch.cuda.empty_cache()\n        gc.collect()\n    prob_data= pd.DataFrame.from_dict(prob_data)\n    prob_data['patient_id'], prob_data['image_nu'],prob_data['split_nu'] = prob_data['ID'].str.split('_').str\n    prob_data[['LAA','CE']] = pd.DataFrame(prob_data.prob.tolist(), index= prob_data.index)\n    prob_data_submission = prob_data.drop(['ID', 'prob','image_nu','split_nu'], axis=1)\n    avg = prob_data_submission.groupby('patient_id',as_index=False).mean()\n    avg = avg[['patient_id','CE','LAA']]\n    return avg\n    ","metadata":{"execution":{"iopub.status.busy":"2022-08-22T21:18:49.336135Z","iopub.execute_input":"2022-08-22T21:18:49.336631Z","iopub.status.idle":"2022-08-22T21:18:49.349317Z","shell.execute_reply.started":"2022-08-22T21:18:49.336600Z","shell.execute_reply":"2022-08-22T21:18:49.348340Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub=submission(test_dl, model)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T21:18:49.350966Z","iopub.execute_input":"2022-08-22T21:18:49.351522Z","iopub.status.idle":"2022-08-22T21:18:58.751948Z","shell.execute_reply.started":"2022-08-22T21:18:49.351482Z","shell.execute_reply":"2022-08-22T21:18:58.750958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv',index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-22T21:18:58.753754Z","iopub.execute_input":"2022-08-22T21:18:58.754114Z","iopub.status.idle":"2022-08-22T21:18:58.762616Z","shell.execute_reply.started":"2022-08-22T21:18:58.754077Z","shell.execute_reply":"2022-08-22T21:18:58.761626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(torch.cuda.memory_summary())","metadata":{"execution":{"iopub.status.busy":"2022-08-22T21:18:58.764040Z","iopub.execute_input":"2022-08-22T21:18:58.764481Z","iopub.status.idle":"2022-08-22T21:18:58.773189Z","shell.execute_reply.started":"2022-08-22T21:18:58.764443Z","shell.execute_reply":"2022-08-22T21:18:58.771953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}