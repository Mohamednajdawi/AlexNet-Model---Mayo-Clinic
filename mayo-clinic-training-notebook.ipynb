{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n\nimport IPython.display\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\nfrom PIL import Image\nfrom glob import glob\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n#import Pyvips\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, train_test_split\nfrom skimage.filters import sobel\nfrom skimage import segmentation\nfrom skimage.color import label2rgb\nfrom skimage.color import rgb2hed, hed2rgb\nfrom skimage.exposure import rescale_intensity\nfrom skimage.measure import regionprops, regionprops_table\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import ndimage as ndi\nfrom matplotlib.patches import Rectangle\nfrom pytorch_lightning.callbacks.early_stopping import EarlyStopping\n\n\n\nimport torchvision\n\nfrom tqdm.auto import tqdm\nfrom tqdm import trange\nfrom time import sleep\nfrom functools import partial\nimport tifffile as tiff\n\nimport cv2 as cv\nfrom openslide import OpenSlide\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom pprint import pprint\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport gc\nimport torchvision.models as models\nimport copy\n\n\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n\nfrom torch.cuda.amp import autocast, GradScaler\nImage.MAX_IMAGE_PIXELS = None\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-19T12:25:45.077414Z","iopub.execute_input":"2022-08-19T12:25:45.078054Z","iopub.status.idle":"2022-08-19T12:25:51.734759Z","shell.execute_reply.started":"2022-08-19T12:25:45.077966Z","shell.execute_reply":"2022-08-19T12:25:51.733599Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"del model_ft\ndel model\ngc.collect()\nprint(torch.cuda.max_memory_allocated(device=device))\ntorch.cuda.empty_cache()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T12:25:51.737454Z","iopub.execute_input":"2022-08-19T12:25:51.738569Z","iopub.status.idle":"2022-08-19T12:25:52.097353Z","shell.execute_reply.started":"2022-08-19T12:25:51.738527Z","shell.execute_reply":"2022-08-19T12:25:52.094991Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3983985907.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel_ft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_memory_allocated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model_ft' is not defined"],"ename":"NameError","evalue":"name 'model_ft' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"# Loading data","metadata":{}},{"cell_type":"code","source":"transformed_train = pd.read_csv('../input/mayo-clinic-output/new_train.csv')\ntrain, vaild = train_test_split(transformed_train, test_size=0.2)\nclasses_name = [\"LAA\",\"CE\"]\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T12:26:06.414936Z","iopub.execute_input":"2022-08-19T12:26:06.415385Z","iopub.status.idle":"2022-08-19T12:26:06.440331Z","shell.execute_reply.started":"2022-08-19T12:26:06.415348Z","shell.execute_reply":"2022-08-19T12:26:06.439301Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Data Loader","metadata":{}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, path, df, transform=None):\n        self.df = df\n        self.path = path\n        self.Image_names = df['image_name'].values\n        self.labels = df['label'].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.Image_names[idx]\n        img= Image.open(os.path.join(self.path, f\"{file_name}.jpg\"))\n        if self.transform:\n            image=self.transform(img)\n\n        label = self.labels[idx]\n\n        return image, torch.tensor(label), file_name","metadata":{"execution":{"iopub.status.busy":"2022-08-19T12:26:07.078647Z","iopub.execute_input":"2022-08-19T12:26:07.079103Z","iopub.status.idle":"2022-08-19T12:26:07.088704Z","shell.execute_reply.started":"2022-08-19T12:26:07.079042Z","shell.execute_reply":"2022-08-19T12:26:07.087550Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Transforms","metadata":{}},{"cell_type":"code","source":"batch_size=64\ndata_transform = transforms.Compose([\n        transforms.Resize((256,256)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                             std=[0.229, 0.224, 0.225])\n    ])\ntrain_dataset = TrainDataset(\"../input/mayo-clinic-output/\", train, transform = data_transform)\nvaild_dataset = TrainDataset(\"../input/mayo-clinic-output/\", vaild, transform = data_transform)\n\ntrain_dl = torch.utils.data.DataLoader(train_dataset,\n                                             batch_size=batch_size, shuffle=True,\n                                             num_workers=0)\nvalid_dl = torch.utils.data.DataLoader(vaild_dataset,\n                                             batch_size=batch_size, shuffle=True,\n                                             num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2022-08-19T12:26:07.792563Z","iopub.execute_input":"2022-08-19T12:26:07.792996Z","iopub.status.idle":"2022-08-19T12:26:07.810873Z","shell.execute_reply.started":"2022-08-19T12:26:07.792958Z","shell.execute_reply":"2022-08-19T12:26:07.809638Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def imshow(axis, inp):\n    \"\"\"Denormalize and show\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    axis.imshow(inp)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T12:26:08.207483Z","iopub.execute_input":"2022-08-19T12:26:08.207919Z","iopub.status.idle":"2022-08-19T12:26:08.221328Z","shell.execute_reply.started":"2022-08-19T12:26:08.207880Z","shell.execute_reply":"2022-08-19T12:26:08.218839Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\"\"\"img, label = next(iter(train_dl))\nprint(img.size(), label.size())\nfig = plt.figure(1, figsize=(16, 4))\ngrid = ImageGrid(fig, 111, nrows_ncols=(8, 10), axes_pad=0.05)    \nfor i in range(img.size()[0]):\n    ax = grid[i]\n    imshow(ax, img[i])\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-08-19T12:26:08.647154Z","iopub.execute_input":"2022-08-19T12:26:08.647608Z","iopub.status.idle":"2022-08-19T12:26:08.658267Z","shell.execute_reply.started":"2022-08-19T12:26:08.647569Z","shell.execute_reply":"2022-08-19T12:26:08.657043Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'img, label = next(iter(train_dl))\\nprint(img.size(), label.size())\\nfig = plt.figure(1, figsize=(16, 4))\\ngrid = ImageGrid(fig, 111, nrows_ncols=(8, 10), axes_pad=0.05)    \\nfor i in range(img.size()[0]):\\n    ax = grid[i]\\n    imshow(ax, img[i])\\n'"},"metadata":{}}]},{"cell_type":"markdown","source":"# PreTrained Model","metadata":{}},{"cell_type":"code","source":"use_gpu = torch.cuda.is_available()\nmodel_ft = models.resnet50(pretrained=True)\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, 2)\nmodel_ft=model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_ft.parameters(), lr=0.01, momentum=0.9)\nexp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T12:26:10.029693Z","iopub.execute_input":"2022-08-19T12:26:10.030171Z","iopub.status.idle":"2022-08-19T12:26:19.809059Z","shell.execute_reply.started":"2022-08-19T12:26:10.030123Z","shell.execute_reply":"2022-08-19T12:26:19.808068Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/97.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1c31793e2904276b520f3923da5f700"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def train_model(dataloders, model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n    use_gpu = torch.cuda.is_available()\n    best_model_wts = model.state_dict()\n    best_acc = 0.0\n    dataset_sizes = {'train': len(dataloders['train'].dataset), \n                     'valid': len(dataloders['valid'].dataset)}\n\n    for epoch in range(num_epochs):\n        for phase in ['train', 'valid']:\n            if phase == 'train':\n                scheduler.step()\n                model.train(True)\n            else:\n                model.train(False)\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels, _ in dataloders[phase]:\n                if use_gpu:\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n                else:\n                    inputs = inputs.to(device)\n                    labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                outputs = model(inputs)\n                _, preds = torch.max(outputs.data, 1)\n                loss = criterion(outputs, labels)\n\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n                running_loss += loss.data\n                running_corrects += torch.sum(preds == labels.data)\n            \n            if phase == 'train':\n                train_epoch_loss = running_loss / dataset_sizes[phase]\n                train_epoch_acc = running_corrects / dataset_sizes[phase]\n            else:\n                valid_epoch_loss = running_loss / dataset_sizes[phase]\n                valid_epoch_acc = running_corrects / dataset_sizes[phase]\n                \n            if phase == 'valid' and valid_epoch_acc > best_acc:\n                best_acc = valid_epoch_acc\n                best_model_wts = model.state_dict()\n\n        print('Epoch [{}/{}] train loss: {:.4f} acc: {:.4f} ' \n              'valid loss: {:.4f} acc: {:.4f}'.format(\n                epoch, num_epochs - 1,\n                train_epoch_loss, train_epoch_acc, \n                valid_epoch_loss, valid_epoch_acc))\n            \n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-08-19T12:26:19.811169Z","iopub.execute_input":"2022-08-19T12:26:19.811558Z","iopub.status.idle":"2022-08-19T12:26:19.823258Z","shell.execute_reply.started":"2022-08-19T12:26:19.811521Z","shell.execute_reply":"2022-08-19T12:26:19.822301Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dloaders = {'train':train_dl, 'valid':valid_dl}\nstart_time = time.time()\nmodel = train_model(dloaders, model_ft, criterion, optimizer, exp_lr_scheduler, num_epochs=12)\nprint('Training time: {:10f} minutes'.format((time.time()-start_time)/60))\n","metadata":{"execution":{"iopub.status.busy":"2022-08-19T12:26:19.824930Z","iopub.execute_input":"2022-08-19T12:26:19.825728Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch [0/11] train loss: 0.0111 acc: 0.6550 valid loss: 0.0234 acc: 0.6739\nEpoch [1/11] train loss: 0.0101 acc: 0.6956 valid loss: 0.0095 acc: 0.6891\nEpoch [2/11] train loss: 0.0075 acc: 0.7677 valid loss: 0.0097 acc: 0.7166\nEpoch [3/11] train loss: 0.0060 acc: 0.8395 valid loss: 0.0152 acc: 0.7194\nEpoch [4/11] train loss: 0.0058 acc: 0.8433 valid loss: 0.0099 acc: 0.6938\nEpoch [5/11] train loss: 0.0035 acc: 0.9101 valid loss: 0.0129 acc: 0.7393\nEpoch [6/11] train loss: 0.0013 acc: 0.9742 valid loss: 0.0104 acc: 0.7839\nEpoch [7/11] train loss: 0.0004 acc: 0.9964 valid loss: 0.0113 acc: 0.7915\nEpoch [8/11] train loss: 0.0002 acc: 0.9979 valid loss: 0.0118 acc: 0.7962\nEpoch [9/11] train loss: 0.0001 acc: 0.9998 valid loss: 0.0123 acc: 0.7991\n","output_type":"stream"}]},{"cell_type":"code","source":"def visualize_model(dataloders, model, num_images=25):\n    cnt = 0\n    fig = plt.figure(1, figsize=(16, 16))\n    grid = ImageGrid(fig, 111, nrows_ncols=(5, 5), axes_pad=0.05)\n    for i, (inputs, labels, file_name) in enumerate(dataloders['valid']):\n        if use_gpu:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n        else:\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n        outputs = model(inputs)\n        _, preds = torch.max(outputs.data, 1)\n\n        for j in range(inputs.size()[0]):\n            ax = grid[cnt]\n            imshow(ax, inputs.cpu().data[j])\n            ax.text(10, 210, 'Name: {} Predicted {} || Actual {}'.format(file_name[j], classes_name[preds[j]], classes_name[labels.data[j]]), \n                    color='k', backgroundcolor='w', alpha=0.8,size=\"small\")\n            cnt += 1\n            if cnt == num_images:\n                return","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_model(dloaders, model)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}